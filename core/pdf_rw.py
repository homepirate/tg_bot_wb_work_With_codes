import os
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Optional, Tuple

import pdfplumber
from PyPDF2 import PdfReader, PdfWriter
from sqlalchemy.ext.asyncio import AsyncSession

from config import config
from services.printed_codes import register_code_if_new
from .patterns import *

# ==============================
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã / –ø—É—Ç–∏ / —Ä–µ–≥—É–ª—è—Ä–∫–∏
# ==============================
#
# PDF_DIR = Path("pdf-codes")
# PDF_DIR.mkdir(exist_ok=True)
#
# _RE_GTIN = re.compile(r"^0\d{13,}$")
# _RE_SERIAL = re.compile(r"^[\x20-\x7E]{4,}$")
# _RE_ASCII_PREFIX = re.compile(r"^([\x21-\x7E]{4,})")  # –≤–∏–¥–∏–º—ã–π ASCII –±–µ–∑ –≤–µ–¥—É—â–µ–≥–æ –ø—Ä–æ–±–µ–ª–∞
#
# # 1) –°–æ —Å–∫–æ–±–∫–∞–º–∏ ‚Äî –≤—Å—ë –≤ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
# _RE_GS1_PAREN_ONELINE = re.compile(
#     r"\(\s*01\s*\)\s*\d{14}\s*\(\s*21\s*\)\s*[!-~]{4,}",
#     re.IGNORECASE
# )
#
# _RE_GS1_NOPAREN_HEADLINE = re.compile(
#     r"^\s*01\s*\d{14}\s*21\s*$",
#     re.IGNORECASE
# )
# _RE_ASCII_PREFIX_LINE = re.compile(r"^\s*([!-~]{4,})")

# ==============================
# –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
# ==============================

@dataclass(frozen=True)
class CutResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç ¬´–≤—ã—Ä–µ–∑–∞–Ω–∏—è¬ª —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ PDF."""
    head_path: Optional[Path]  # –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≤—ã—Ä–µ–∑–∞–Ω–Ω–æ–π ¬´—à–∞–ø–∫–æ–π¬ª (None, –µ—Å–ª–∏ –Ω–µ –≤—ã—Ä–µ–∑–∞–ª–∏)
    shortage: int              # –Ω–µ—Ö–≤–∞—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü (>= 0)


# ==============================
# –ù–µ–±–æ–ª—å—à–∏–µ —É—Ç–∏–ª–∏—Ç—ã
# ==============================

def _compile_size_regex(size_raw: str) -> re.Pattern:
    """
    –°—Ç—Ä–æ–≥–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞.
    - –ë—É–∫–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã (XS, S, M, L, XL, XXL, XXXL, 2XL..5XL) ‚Äî –Ω–µ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å —Ä—è–¥–æ–º –±—É–∫–≤/—Ü–∏—Ñ—Ä.
    - –ß–∏—Å–ª–æ–≤—ã–µ –∏ –¥–∏–∞–ø–∞–∑–æ–Ω—ã (50, 50-52, 50/52) ‚Äî —Ç—Ä–µ–±—É–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Ç–æ–∫–µ–Ω–∞.
    """
    s = re.sub(r"\s+", "", str(size_raw)).upper()

    # –ë—É–∫–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã (+ 2XL..5XL)
    if re.fullmatch(r"[2-5]?(?:XS|S|M|L|XL|XXL|XXXL)", s):
        # –Ω–µ—Ç –±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã —Å–ª–µ–≤–∞ –∏ —Å–ø—Ä–∞–≤–∞
        return re.compile(
            rf"(?:—Ä–∞–∑–º–µ—Ä:\s*)?(?<![A-Z0-9]){re.escape(s)}(?![A-Z0-9])",
            re.IGNORECASE | re.MULTILINE,
        )

    # –ß–∏—Å–ª–æ–≤—ã–µ/–¥–∏–∞–ø–∞–∑–æ–Ω—ã: —Ä–∞–∑—Ä–µ—à–∞–µ–º -, ‚Äì, /
    token = re.escape(s).replace(r"\-", r"[‚Äì\-\/]")
    return re.compile(
        rf"(?:—Ä–∞–∑–º–µ—Ä:\s*)?(?<!\w){token}(?!\w)",
        re.IGNORECASE | re.MULTILINE,
    )


def _assert_exists(path: Path) -> None:
    if not path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

def _write_pdf(writer: PdfWriter, out_path: Path) -> None:
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with open(out_path, "wb") as f:
        writer.write(f)

def _replace_file(tmp_path: Path, target: Path) -> None:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Ñ–∞–π–ª–∞ –Ω–∞ –¥–∏—Å–∫–µ."""
    os.replace(tmp_path, target)

def _ascii_prefix(line: str) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ–¥—É—â—É—é –ø–æ–¥–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–∏–º—ã—Ö ASCII-—Å–∏–º–≤–æ–ª–æ–≤ (–µ—Å–ª–∏ –¥–ª–∏–Ω–∞ >= 4)."""
    m = RE_ASCII_PREFIX.match(line)
    return m.group(1) if m else None

def _page_lines(pl_page) -> list[str]:
    """–î–æ—Å—Ç–∞—ë—Ç —Å—Ç—Ä–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã pdfplumber —Å –º–∞–ª–æ–π —Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å—é."""
    txt = pl_page.extract_text(x_tolerance=1.0, y_tolerance=1.0) or ""
    return [ln.strip() for ln in txt.splitlines() if ln.strip()]

def _strip_all_ws(s: str) -> str:
    """–ù–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä + —É–¥–∞–ª–∏—Ç—å –≤—Å–µ –ø—Ä–æ–±–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (–≤–∫–ª—é—á–∞—è \\n, \\t)."""
    return re.sub(r"\s+", "", s).lower()

def _extract_code_from_lines(lines: Iterable[str]) -> Optional[str]:
    """
    –ò—â–µ–º –∫–æ–¥ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ GTIN. –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–∫–ª–µ–µ–Ω–∞ ‚Äî –±–µ—Ä—ë–º ASCII-–ø—Ä–µ—Ñ–∏–∫—Å.
    –§–æ–ª–ª–±—ç–∫: –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞, –Ω–∞—á–∏–Ω–∞—é—â–∞—è—Å—è —Å –≤–∏–¥–∏–º—ã—Ö ASCII.
    """
    after_gtin = False
    for ln in lines:
        if RE_GTIN.match(ln):
            after_gtin = True
            continue
        if after_gtin:
            prefix = _ascii_prefix(ln)
            if prefix:
                return prefix

    for ln in lines:
        prefix = _ascii_prefix(ln)
        if prefix:
            return prefix
    return None


def _extract_code_from_text(text: str) -> Optional[str]:
    """
    A) '(01)<14>(21)<ASCII‚Ä¶>' ‚Äî –≤ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ ‚Üí –≤–µ—Ä–Ω—É—Ç—å —Ü–µ–ª–∏–∫–æ–º (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤).
    B) '01<14>21' ‚Äî ¬´–≥–æ–ª–æ–≤–∞¬ª –Ω–∞ —Å—Ç—Ä–æ–∫–µ i; —Å–µ—Ä–∏–∞–ª ‚Äî –≤ –æ–¥–Ω–æ–π –∏–∑ –±–ª–∏–∂–∞–π—à–∏—Ö –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫,
       –∏—â–µ–º –ø–µ—Ä–≤—ã–π –ø—Ä–µ—Ñ–∏–∫—Å –ø–µ—á–∞—Ç–Ω–æ–≥–æ ASCII (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∏—Ä–∏–ª–ª–∏—Ü—É/—Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏).
    –ò–Ω–∞—á–µ ‚Äî –∫–æ–¥–∞ –Ω–µ—Ç.
    """
    if not text:
        return None

    # A) —Å–æ —Å–∫–æ–±–∫–∞–º–∏ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
    m = RE_GS1_PAREN_ONELINE.search(text)
    if m:
        return re.sub(r"\s+", "", m.group(0))

    # B) –±–µ–∑ —Å–∫–æ–±–æ–∫: –∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Å–µ—Ä–∏–∞–ª –≤ –±–ª–∏–∂–∞–π—à–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    max_lookahead = 5  # —Å–∫–æ–ª—å–∫–æ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫ –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –≤ –ø–æ–∏—Å–∫–∞—Ö ASCII-—Å–µ—Ä–∏–∞–ª–∞
    for i, ln in enumerate(lines):
        if RE_GS1_NOPAREN_HEADLINE.match(ln):
            # –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑ —ç—Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
            m_same = re.search(r"(?:\(\s*21\s*\)|21)\s*([!-~]{4,})", ln, re.IGNORECASE)
            if m_same:
                head = re.sub(r"\s+", "", ln[:m_same.start(1)])
                tail = re.sub(r"\s+", "", m_same.group(1))
                return head + tail

            # —Å–º–æ—Ç—Ä–∏–º –±–ª–∏–∂–∞–π—à–∏–µ N —Å—Ç—Ä–æ–∫ –Ω–∞ —Å–µ—Ä–∏–∞–ª (ASCII-–ø—Ä–µ—Ñ–∏–∫—Å)
            for j in range(i + 1, min(i + 1 + max_lookahead, len(lines))):
                m_next = RE_ASCII_PREFIX_LINE.match(lines[j])
                if m_next:
                    head = re.sub(r"\s+", "", ln)               # 01<14>21
                    tail = re.sub(r"\s+", "", m_next.group(1))  # ASCII-—Å–µ—Ä–∏–∞–ª
                    return head + tail

    return None

# ==============================
# –†–∞–±–æ—Ç–∞ —Å PDF-–∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
# ==============================

def read_pdf(file_path: str | Path) -> str:
    """
    –°—á–∏—Ç—ã–≤–∞–µ—Ç –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞ —Å –ø–æ–º–æ—â—å—é pdfplumber.
    :return: —Ç–µ–∫—Å—Ç –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
    """
    path = Path(file_path)
    _assert_exists(path)

    text_parts: list[str] = []
    with pdfplumber.open(str(path)) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text_parts.append(page_text.strip())
    return "\n".join(text_parts)

async def save_pdf_file(data: bytes, filename: str, user_id: int) -> Path:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç PDF –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é pdf-codes.
    –ò–º—è —Ñ–∞–π–ª–∞ = <user_id>_<filename>.
    """
    save_path = PDF_DIR / f"{user_id}_{filename}"
    with open(save_path, "wb") as f:
        f.write(data)
    return save_path


# ==============================
# –ü–æ–∏—Å–∫ PDF –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –∏ —Ä–∞–∑–º–µ—Ä—É
# ==============================

def _normalize_for_search(s: str) -> str:
    """–£–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫/–º–Ω–æ–≥–æ–ø—Ä–æ–±–µ–ª ‚Äî —É–¥–æ–±–Ω–æ –∏—Å–∫–∞—Ç—å –∞—Ä—Ç–∏–∫—É–ª, –ø–æ—Ä–≤–∞–Ω–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏."""
    return re.sub(r"\s+", " ", s).strip().lower()


def find_pdfs_by_article_size_all(article: str, size: str) -> list[Path]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –í–°–ï PDF –∏–∑ PDF_DIR, –≥–¥–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –ò –∞—Ä—Ç–∏–∫—É–ª, –ò —Ä–∞–∑–º–µ—Ä.
    –ü–æ—Ä—è–¥–æ–∫ ‚Äî –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞.
    """
    results: list[Path] = []
    if article is None or size is None:
        return results

    a_no_ws = _strip_all_ws(str(article))
    s = str(size).strip()
    if not a_no_ws or not s:
        return results

    size_regex = _compile_size_regex(s)

    for pdf_file in PDF_DIR.glob("*.pdf"):
        try:
            raw_text = read_pdf(pdf_file)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {pdf_file}: {e}")
            continue

        # üîß –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–∏—Ä–µ ‚Äî –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–π –≤–µ—Ä—Å—Ç–∫–µ
        raw_text_norm = raw_text.replace("‚Äì", "-").replace("‚Äî", "-")

        # 1) –ê—Ä—Ç–∏–∫—É–ª –∏—â–µ–º –ø–æ ¬´—Å–ø–ª—é—â–µ–Ω–Ω–æ–º—É¬ª —Ç–µ–∫—Å—Ç—É (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ –ø–µ—Ä–µ–Ω–æ—Å–∞–º)
        text_no_ws = _strip_all_ws(raw_text)
        if a_no_ws not in text_no_ws:
            continue

        # 2) –†–∞–∑–º–µ—Ä –∏—â–µ–º –¢–û–õ–¨–ö–û –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É (–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É) —Ç–µ–∫—Å—Ç—É,
        #    —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã —Ç–æ–∫–µ–Ω–æ–≤
        if size_regex.search(raw_text_norm):
            results.append(pdf_file)

    results.sort(key=lambda p: p.name.lower())
    return results


# ==============================
# –õ–æ–≥–∏–∫–∞ –≤—ã—Ä–µ–∑–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
# ==============================

def _build_tail_writer(reader: PdfReader, total: int, keep_indexes: set[int]) -> PdfWriter:
    """–°–æ–∑–¥–∞—ë—Ç writer –∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å."""
    tail_writer = PdfWriter()
    for i in range(total):
        if i in keep_indexes:
            tail_writer.add_page(reader.pages[i])
    return tail_writer

def _extract_page_code(pl_pdf, page_index: int) -> Optional[str]:
    """–ö–æ–¥ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ –µ—ë –∏–Ω–¥–µ–∫—Å—É (—É—á–∏—Ç—ã–≤–∞–µ—Ç GS1-–ø–∞—Ä—É –∏ fallback)."""
    txt = pl_pdf.pages[page_index].extract_text(x_tolerance=1.0, y_tolerance=1.0) or ""
    return _extract_code_from_text(txt)

async def cut_first_n_pages_unique(
    session: AsyncSession,
    src_pdf: Path | str,
    n: int,
) -> Tuple[Optional[Path], int]:
    """
    –í—ã—Ä–µ–∑–∞–µ—Ç –ø–µ—Ä–≤—ã–µ n —Å—Ç—Ä–∞–Ω–∏—Ü, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –ù–û–í–´–ï –∫–æ–¥—ã (—á–µ—Ä–µ–∑ register_code_if_new).
    –î—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è—é—Ç—Å—è –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–ø—É—Ç—å –∫ —à–∞–ø–∫–µ, –Ω–µ—Ö–≤–∞—Ç–∫–∞).
    """
    src = Path(src_pdf)
    _assert_exists(src)
    if n <= 0:
        return None, 0

    tmp_dir = src.parent / "tmp"
    tmp_dir.mkdir(parents=True, exist_ok=True)

    reader = PdfReader(str(src))
    total_pages = len(reader.pages)

    to_delete: set[int] = set()
    head_writer = PdfWriter()
    unique_taken = 0

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º pdfplumber –æ–¥–∏–Ω —Ä–∞–∑ ‚Äî —á–∏—Ç–∞–µ–º –∫–æ–¥—ã –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ
    with pdfplumber.open(str(src)) as pl_pdf:
        for i in range(total_pages):
            if unique_taken >= n:
                break

            code = _extract_page_code(pl_pdf, i)
            if not code:
                # –Ω–µ—Ç –∫–æ–¥–∞ ‚Äî —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
                continue

            is_new = await register_code_if_new(session, code)
            if is_new:
                head_writer.add_page(reader.pages[i])
                to_delete.add(i)
                unique_taken += 1
            else:
                # –¥—É–±–ª–∏–∫–∞—Ç –∫–æ–¥–∞ ‚Äî —Ç–æ–∂–µ —É–¥–∞–ª—è–µ–º –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞
                to_delete.add(i)

    # –ï—Å–ª–∏ –Ω–µ –≤–∑—è–ª–∏ –Ω–∏ –æ–¥–Ω–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ–π ‚Äî –º–æ–≥–ª–∏ –ª–∏—à—å —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏
    if unique_taken == 0:
        if to_delete:
            keep = set(range(total_pages)) - to_delete
            tail_writer = _build_tail_writer(reader, total_pages, keep)
            if len(tail_writer.pages) > 0:
                tail_tmp = tmp_dir / f"{src.stem}__tail_tmp.pdf"
                _write_pdf(tail_writer, tail_tmp)
                _replace_file(tail_tmp, src)
            else:
                try:
                    src.unlink()
                except FileNotFoundError:
                    pass
        return None, max(0, n - unique_taken)

    # –ü–∏—à–µ–º —à–∞–ø–∫—É (–≤—ã—Ä–µ–∑–∞–Ω–Ω—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ)
    head_out = tmp_dir / f"{src.stem}__head_{unique_taken}.pdf"
    _write_pdf(head_writer, head_out)

    # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º –∏—Å—Ö–æ–¥–Ω–∏–∫ –±–µ–∑ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö
    keep = set(range(total_pages)) - to_delete
    if keep:
        tail_writer = _build_tail_writer(reader, total_pages, keep)
        tail_tmp = tmp_dir / f"{src.stem}__tail_tmp.pdf"
        _write_pdf(tail_writer, tail_tmp)
        _replace_file(tail_tmp, src)
    else:
        try:
            src.unlink()
        except FileNotFoundError:
            pass

    return head_out, max(0, n - unique_taken)


# ==============================
# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ PDF –ø–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É
# ==============================

def merge_pdfs(pdf_paths: list[Path | str], output_path: Path | str) -> Path:
    """
    –°–∫–ª–µ–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ PDF –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª output_path.
    –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã.
    """
    writer = PdfWriter()
    for p in pdf_paths:
        pth = Path(p)
        if not pth.exists():
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –ø—Ä–∏ —Å–∫–ª–µ–π–∫–µ: {pth}")
            continue
        reader = PdfReader(str(pth))
        for page in reader.pages:
            writer.add_page(page)

    out = Path(output_path)
    out.parent.mkdir(parents=True, exist_ok=True)
    with open(out, "wb") as f:
        writer.write(f)
    return out


def _normalize_columns(df) -> tuple[int, int, int]:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫.
    –¢—Ä–µ–±—É—é—Ç—Å—è: '–∞—Ä—Ç–∏–∫—É–ª','—Ä–∞–∑–º–µ—Ä','–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã —ç—Ç–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.
    """
    required = {"–∞—Ä—Ç–∏–∫—É–ª", "—Ä–∞–∑–º–µ—Ä", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"}
    cols_norm = [str(c).strip().lower() for c in df.columns]
    colset = set(cols_norm)
    if not required.issubset(colset):
        missing = required - colset
        raise ValueError(f"–í df –Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {', '.join(sorted(missing))}")

    return (
        cols_norm.index("–∞—Ä—Ç–∏–∫—É–ª"),
        cols_norm.index("—Ä–∞–∑–º–µ—Ä"),
        cols_norm.index("–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
    )

def _append_shortage(shortages: list[str], article: str, size: str, amount: int) -> None:
    shortages.append(f"{article} - —Ä–∞–∑–º–µ—Ä: {size}, –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ: {amount}")

async def build_pdf_from_dataframe(df, output_path: Path | str | None = None) -> tuple[Optional[Path], Optional[str]]:
    """
    –ü—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ df ('–∞—Ä—Ç–∏–∫—É–ª','—Ä–∞–∑–º–µ—Ä','–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'):
      - –∏—â–µ—Ç PDF –ø–æ (–∞—Ä—Ç–∏–∫—É–ª+—Ä–∞–∑–º–µ—Ä),
      - –≤—ã—Ä–µ–∑–∞–µ—Ç –ø–µ—Ä–≤—ã–µ '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ' —Å—Ç—Ä–∞–Ω–∏—Ü, –Ω–æ —Ç–æ–ª—å–∫–æ —Å –ù–û–í–´–ú–ò –∫–æ–¥–∞–º–∏ (consume),
      - –∫–æ–ø–∏—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è —Å–∫–ª–µ–π–∫–∏,
      - —Å–æ–±–∏—Ä–∞–µ—Ç –æ–±—â–∏–π –æ—Ç—á—ë—Ç –æ –Ω–µ—Ö–≤–∞—Ç–∫–∞—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (–≤ —Ç.—á. –µ—Å–ª–∏ PDF –Ω–µ –Ω–∞–π–¥–µ–Ω).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–ø—É—Ç—å –∫ –∏—Ç–æ–≥–æ–≤–æ–º—É PDF –∏–ª–∏ None, —Ç–µ–∫—Å—Ç –æ—Ç—á—ë—Ç–∞ –∏–ª–∏ None).
    """
    idx_article, idx_size, idx_qty = _normalize_columns(df)

    cut_parts: list[Path] = []
    shortages: list[str] = []

    # –æ–¥–Ω–∞ —Å–µ—Å—Å–∏—è –Ω–∞ –≤—Å—é —Å–±–æ—Ä–∫—É
    async with config.AsyncSessionLocal() as session:
        for _, row in df.iterrows():
            article = str(row.iloc[idx_article]).strip()
            size = str(row.iloc[idx_size]).strip()

            # –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ int
            try:
                qty = int(row.iloc[idx_qty])
            except Exception:
                continue
            if qty <= 0:
                continue

            # –ò—â–µ–º –í–°–ï —Ñ–∞–π–ª—ã —Å —Ç–∞–∫–∏–º –∞—Ä—Ç–∏–∫—É–ª–æ–º/—Ä–∞–∑–º–µ—Ä–æ–º
            pdf_paths = find_pdfs_by_article_size_all(article, size)
            if not pdf_paths:
                _append_shortage(shortages, article, size, qty)
                continue

            remaining = qty
            took_total = 0

            for src_pdf_path in pdf_paths:
                if remaining <= 0:
                    break

                try:
                    part_path, shortage = await cut_first_n_pages_unique(session, src_pdf_path, remaining)
                    # cut_first_n_pages_unique –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç shortage >= 0 –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö remaining
                    took_now = max(0, remaining - shortage)

                    if took_now > 0 and part_path is not None:
                        # —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–µ –ø—É—Å—Ç–æ–π
                        rr = PdfReader(str(part_path))
                        if len(rr.pages) > 0:
                            cut_parts.append(part_path)
                        else:
                            try:
                                Path(part_path).unlink(missing_ok=True)
                            except Exception:
                                pass

                    took_total += took_now
                    remaining -= took_now

                except Exception:
                    # –ª—é–±–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–∑–∫–µ –∏–∑ —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ ‚Äî —Å—á–∏—Ç–∞–µ–º –∫–∞–∫ –±—É–¥—Ç–æ –∏–∑ –Ω–µ–≥–æ 0
                    # –∏ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Ñ–∞–π–ª
                    pass

            if remaining > 0:
                # –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–∞–∂–µ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–±–æ—Ä–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
                _append_shortage(shortages, article, size, remaining)

        # —Ñ–∏–∫—Å–∏—Ä—É–µ–º –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–¥—ã –æ–¥–∏–Ω —Ä–∞–∑
        await session.commit()

    if not cut_parts:
        report = "\n".join(shortages) if shortages else None
        return None, report

    result_path = merge_pdfs(cut_parts, output_path or (PDF_DIR / "result.pdf"))

    # –æ—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫—É—Å–∫–æ–≤
    for p in cut_parts:
        try:
            Path(p).unlink(missing_ok=True)
        except Exception:
            pass

    report = "\n".join(shortages) if shortages else None
    return result_path, report
