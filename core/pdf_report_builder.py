from pathlib import Path
from datetime import datetime
from typing import Optional, Tuple, List
import io
import re

import pandas as pd
import pdfplumber
from PyPDF2 import PdfReader

from .patterns import *


__all__ = [
    "build_inventory_report_excel_bytes",
]


# # ===== –†–µ–≥—É–ª—è—Ä–∫–∏ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±–æ–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –≤–µ—Ä—Å—Ç–∫–∏) =====
# # –ê—Ä—Ç–∏–∫—É–ª: —Ä–µ–∂–µ–º –¥–æ "–¶–≤–µ—Ç" (–µ—Å–ª–∏ —Å–∫–ª–µ–µ–Ω–æ), –∏–Ω–∞—á–µ –¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–∫–∏.
#
# _RE_ART = re.compile(
#     r"–ê—Ä—Ç–∏–∫—É–ª\s*[:\-]?\s*(.+?)(?=(?:\s*–¶–≤–µ—Ç\s*:|\s*–†–∞–∑–º–µ—Ä\s*:|$))",
#     re.IGNORECASE
# )
# # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –∞—Ä—Ç–∏–∫—É–ª–∞
# _RE_ART_ALT1 = re.compile(r"–∞—Ä—Ç\.\s*([A-Z0-9_]+/\S+)", re.IGNORECASE)
# # –û–±—â–∏–π —Ç–æ–∫–µ–Ω "XXX/yyy" (–ª–∞—Ç/—Ü–∏—Ñ—Ä—ã/–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è –¥–æ '/', –∑–∞—Ç–µ–º –∫–∏—Ä/–ª–∞—Ç/—Ü–∏—Ñ—Ä—ã/–¥–µ—Ñ–∏—Å—ã/–ø–æ–¥—á—ë—Ä–∫–∏)
# _RE_ART_ALT2 = re.compile(r"\b([A-Z0-9_]+/[A-Za-z–ê-–Ø–∞-—è0-9_\-]+)\b", re.IGNORECASE)
#
# _RE_COLOR = re.compile(r"–¶–≤–µ—Ç:\s*([^\r\n]+)", re.IGNORECASE)
# _RE_NAME_COLOR = re.compile(r"–ë–∞–ª–∞–∫–ª–∞–≤–∞\s+(.+?)\s+—Ä\.", re.IGNORECASE | re.DOTALL)
# _RE_COLOR_TOKEN = re.compile(r"–¶–≤–µ—Ç", re.IGNORECASE)
#
# # –ß–∏—Å–ª–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã: 56-60, 56‚Äì60, 56/58, –æ–¥–∏–Ω–æ—á–Ω–æ–µ 56
# _RE_SIZE_NUMERIC = re.compile(r"\b\d{2}(?:[‚Äì\-\/]\d{2})?\b")
#
# # –ë—É–∫–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –∏ –ø–∞—Ä—ã.
# # –¶–ò–§–†–ê —Ä–∞–∑—Ä–µ—à–µ–Ω–∞ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–¥ XS/XL/XXL/XXXL (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2XL, 3XL), –Ω–æ –ù–ï –ø–µ—Ä–µ–¥ –æ–¥–∏–Ω–æ—á–Ω—ã–º L/S/M ‚Üí "5L" –Ω–µ –º–∞—Ç—á–∏—Ç—Å—è.
# _RE_SIZE_ALPHA = re.compile(
#     r"""
#     \b(
#         (?:XS|S|M|L|XL|XXL|XXXL)                          # –æ–±—ã—á–Ω—ã–µ
#         |
#         (?:[2-5](?:XS|XL|XXL|XXXL))                       # 2XS, 2XL, 3XL, 4XL, 5XL
#     )
#     (?:[\/\-‚Äì]
#         (?:XS|S|M|L|XL|XXL|XXXL|[2-5](?:XS|XL|XXL|XXXL))  # –ø–∞—Ä—ã: S/M, L‚ÄìXL, 3XL/4XL –∏ —Ç.–ø.
#     )?
#     \b
#     """,
#     re.IGNORECASE | re.VERBOSE,
# )
#
# _SIZE_WORDS = {
#     "ONE SIZE", "ONESIZE", "UNI", "UNISIZE", "UNIVERSAL",
#     "–£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô", "–ï–î–ò–ù–´–ô –†–ê–ó–ú–ï–†", "–î–ï–¢–°–ö–ò–ô", "–ü–û–î–†–û–°–¢–ö–û–í–´–ô",
# }
# _RE_SIZE_WORD = re.compile(r"\b[A-Za-z–ê-–Ø–∞-—è–Å—ë\- ]{3,}\b", re.IGNORECASE)
#

# ===== –£—Ç–∏–ª–∏—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞ =====
def _heal_linebreaks(raw: str) -> str:
    """
    –°–∫–ª–µ–∏–≤–∞–µ—Ç —Ä–∞–∑—Ä—ã–≤—ã –≤–Ω—É—Ç—Ä–∏ —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–æ—Å–ª–µ '/':
      '–±–µ–ª\\n—ã–π' -> '–±–µ–ª—ã–π', '/\\n' -> '/'
    """
    t = raw or ""
    t = re.sub(r"/\s*\n\s*", "/", t)  # '/\n' -> '/'
    t = re.sub(r"([A-Za-z–ê-–Ø–∞-—è–Å—ë])\s*\n\s*([A-Za-z–ê-–Ø–∞-—è–Å—ë])", r"\1\2", t)  # '—Å–ª–æ\n–≤–æ' -> '—Å–ª–æ–≤–æ'
    t = re.sub(r"[ \t]+", " ", t)
    return t


def _first_page_text(pdf_path: Path) -> str:
    with pdfplumber.open(str(pdf_path)) as pdf:
        if not pdf.pages:
            return ""
        raw = pdf.pages[0].extract_text() or ""
        return _heal_linebreaks(raw)


def _clean_size(s: str) -> str:
    s = s.strip()
    s = re.sub(r"[‚Äì‚Äî]", "-", s)                 # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–∏—Ä–µ
    s = re.sub(r"\s*([\-\/])\s*", r"\1", s)     # –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ - –∏ /
    s = re.sub(r"\s+", " ", s)
    return s


def _extract_size_from_text(text: str) -> Optional[str]:
    # –£–¥–∞–ª—è–µ–º GS1-–±–ª–æ–∫–∏, —á—Ç–æ–±—ã —Å–µ—Ä–∏–∞–ª –Ω–µ –º–µ—à–∞–ª —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, '(21)5l-...' ‚Üí '5L').
    text = re.sub(r"\(01\)\s*\d{14}", " ", text)
    text = re.sub(r"\(21\)\s*[!-~]{4,}", " ", text)

    # 1) –Ø–≤–Ω–∞—è –º–µ—Ç–∫–∞ "–†–∞–∑–º–µ—Ä:"
    m = re.search(r"–†–∞–∑–º–µ—Ä:\s*([^\r\n]+)", text, re.IGNORECASE)
    if m:
        return _clean_size(m.group(1))
    # 2) –ë—É–∫–≤–µ–Ω–Ω—ã–µ —Å–æ—á–µ—Ç–∞–Ω–∏—è
    m = RE_SIZE_ALPHA.search(text)
    if m:
        return _clean_size(m.group(0).upper())
    # 3) –ß–∏—Å–ª–æ–≤—ã–µ
    m = RE_SIZE_NUMERIC.search(text)
    if m:
        return _clean_size(m.group(0))
    # 4) –°–ª–æ–≤–µ—Å–Ω—ã–µ
    words_upper = {w.upper() for w in SIZE_WORDS}
    for m in RE_SIZE_WORD.finditer(text):
        cand = _clean_size(m.group(0))
        if cand.upper() in words_upper:
            return cand.upper() if re.search(r"[A-Za-z]", cand) else cand
    return None


def _dedupe_concat(s: str) -> str:
    """–°—Ö–ª–æ–ø—ã–≤–∞–µ—Ç –¥—É–±–ª–∏ ¬´X X X¬ª —Å–ª–∏—Ç—ã–µ –ø–æ–¥—Ä—è–¥ –±–µ–∑ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è: 'XX' -> 'X', 'XXX' -> 'X'."""
    while True:
        m = re.fullmatch(r"(.+?)\1+", s)
        if not m:
            return s
        s = m.group(1)


def _cleanup_article(s: str) -> str:
    # –æ—Ç—Ä–µ–∑–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –ª—é–±–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è "–¶–≤–µ—Ç" (–≤ —Ç.—á. —Å–ª–∏—Ç–Ω–æ–≥–æ), —É–±–∏—Ä–∞–µ–º –¥–≤–æ–µ—Ç–æ—á–∏–µ –∏ –¥—É–±–ª–∏
    s = RE_COLOR_TOKEN.split(s, maxsplit=1)[0]
    s = s.rstrip(":").strip()
    s = _dedupe_concat(s)
    return s


def _extract_article(text: str) -> Optional[str]:
    # 1) '–ê—Ä—Ç–∏–∫—É–ª ...' –¥–æ '–¶–≤–µ—Ç'
    m = RE_ART.search(text)
    if m:
        return _cleanup_article(m.group(1).strip())
    # 2) '–∞—Ä—Ç. XXX/yyy'
    m = RE_ART_ALT1.search(text)
    if m:
        return _cleanup_article(m.group(1).strip())
    # 3) –æ–±—â–∏–π —Ç–æ–∫–µ–Ω "XXX/yyy"
    m = RE_ART_ALT2.search(text)
    if m:
        return _cleanup_article(m.group(1).strip())
    return None


def _extract_color(text: str, article: Optional[str]) -> Optional[str]:
    m = RE_COLOR.search(text)
    if m:
        return m.group(1).strip()
    m = RE_NAME_COLOR.search(text)
    if m:
        return m.group(1).strip()
    if article and "/" in article:
        return article.split("/", 1)[1].strip()
    return None


def _extract_meta_from_first_page(pdf_path: Path) -> Tuple[str, str, str]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä: —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –¥–ª—è ¬´–ø–µ—Ä–≤–æ–≥–æ¬ª, –∏ –¥–ª—è ¬´–≤—Ç–æ—Ä–æ–≥–æ¬ª –≤–∞—Ä–∏–∞–Ω—Ç–∞ –º–∞–∫–µ—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∞—Ä—Ç–∏–∫—É–ª, —Ä–∞–∑–º–µ—Ä, —Ü–≤–µ—Ç); –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏.
    """
    txt = _first_page_text(pdf_path)
    article = _extract_article(txt) or ""
    size = _extract_size_from_text(txt) or ""
    color = _extract_color(txt, article) or ""
    if article:
        article = _cleanup_article(article)  # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞
    return article, size, color


def _pages_count(pdf_path: Path) -> int:
    return len(PdfReader(str(pdf_path)).pages)


def _is_tmp_name(name: str) -> bool:
    n = name.lower()
    return ("__head_" in n) or ("__tail_" in n) or ("tmp" in n)


# ===== –ü—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Å–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç BYTES Excel =====
async def build_inventory_report_excel_bytes(
    directory: Path | str = PDF_DIR,
    include_tmp_files: bool = False,
) -> tuple[bytes, str]:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (bytes, filename) Excel-—Ñ–∞–π–ª–∞ (–Ω–∏—á–µ–≥–æ –Ω–µ –ø–∏—à–µ–º –Ω–∞ –¥–∏—Å–∫).
    –ö–æ–ª–æ–Ω–∫–∏: –∞—Ä—Ç–∏–∫—É–ª | —Ä–∞–∑–º–µ—Ä | —Ü–≤–µ—Ç | –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –¥—É–±–ª–∏ (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∞—Ä—Ç–∏–∫—É–ª, —Ä–∞–∑–º–µ—Ä, —Ü–≤–µ—Ç) ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–º–º–∏—Ä—É–µ—Ç—Å—è.
    """
    directory = Path(directory)
    directory.mkdir(parents=True, exist_ok=True)

    rows: list[dict] = []
    for pdf_path in sorted(directory.glob("*.pdf")):
        name = pdf_path.name
        if not include_tmp_files and _is_tmp_name(name):
            continue
        try:
            article, size, color = _extract_meta_from_first_page(pdf_path)
            count = _pages_count(pdf_path)
        except Exception:
            # –±–∏—Ç—ã–µ/–Ω–µ—á–∏—Ç–∞–µ–º—ã–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue

        rows.append({
            "–∞—Ä—Ç–∏–∫—É–ª": str(article).strip(),
            "—Ä–∞–∑–º–µ—Ä": str(size).split()[0].strip(),
            "—Ü–≤–µ—Ç": str(color).lower().strip(),
            "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ": int(count),
        })

    import pandas as pd, io
    from datetime import datetime

    df = pd.DataFrame(rows, columns=["–∞—Ä—Ç–∏–∫—É–ª", "—Ä–∞–∑–º–µ—Ä", "—Ü–≤–µ—Ç", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"])

    # üßÆ –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–∞—Ä—Ç–∏–∫—É–ª + —Ä–∞–∑–º–µ—Ä + —Ü–≤–µ—Ç) –∏ —Å—É–º–º–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    if not df.empty:
        df = (
            df.groupby(["–∞—Ä—Ç–∏–∫—É–ª", "—Ä–∞–∑–º–µ—Ä", "—Ü–≤–µ—Ç"], as_index=False, dropna=False)
              .agg({"–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ": "sum"})
              .sort_values(["–∞—Ä—Ç–∏–∫—É–ª", "—Ä–∞–∑–º–µ—Ä", "—Ü–≤–µ—Ç"], ignore_index=True)
        )

    # –°–æ–±–∏—Ä–∞–µ–º Excel –≤ –ø–∞–º—è—Ç–∏
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"report_{ts}.xlsx"
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="report")
    buf.seek(0)
    return buf.read(), filename
